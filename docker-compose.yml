# ---------------------------------------------------------------------------
# Extension field â€” shared Airflow container config (YAML anchor)
# ---------------------------------------------------------------------------

x-airflow-common: &airflow-common
  build:
    context: .
    dockerfile: docker/Dockerfile.airflow
  environment: &airflow-common-env
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__CORE__AUTH_MANAGER: airflow.providers.fab.auth_manager.fab_auth_manager.FabAuthManager
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-db/airflow
    AIRFLOW__CORE__LOAD_EXAMPLES: "false"
    AIRFLOW__WEBSERVER__EXPOSE_CONFIG: "true"
    AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags
    AIRFLOW__CORE__EXECUTION_API_SERVER_URL: http://airflow-apiserver:8080/execution/
    AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: "true"
    AIRFLOW__CORE__SECRET_KEY: "visionops-airflow-secret-key"
    AIRFLOW__API_AUTH__JWT_SECRET: "visionops-airflow-jwt-secret"
    PYTHONPATH: /opt/airflow
    MLFLOW_TRACKING_URI: http://mlflow:5000
    YOLO_DATASETS_DIR: /opt/airflow
  volumes:
    - ./dags:/opt/airflow/dags:ro
    - ./src:/opt/airflow/src:ro
    - ./configs:/opt/airflow/configs
    - ./data:/opt/airflow/data
    - ./runs:/opt/airflow/runs
    - airflow-logs:/opt/airflow/logs
  profiles:
    - airflow

# ---------------------------------------------------------------------------
# Services
# ---------------------------------------------------------------------------

services:

  # --- Base stack (make up) ------------------------------------------------

  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.19.0
    command:
      - mlflow
      - server
      - --host
      - "0.0.0.0"
      - --port
      - "5000"
      - --backend-store-uri
      - sqlite:///mlflow/mlflow.db
      - --artifacts-destination
      - /mlflow/artifacts
    ports:
      - "5001:5000"
    volumes:
      - mlflow-data:/mlflow
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:5000/health')"]
      interval: 15s
      timeout: 5s
      retries: 5

  inference:
    build:
      context: .
      dockerfile: docker/Dockerfile.inference
    ports:
      - "8000:8000"
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - MLFLOW_MODEL_NAME=visionops-yolov8n
      - MLFLOW_MODEL_ALIAS=production
    depends_on:
      mlflow:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  prometheus:
    image: prom/prometheus:v3.1.0
    ports:
      - "9090:9090"
    command:
      - --config.file=/etc/prometheus/prometheus.yml
      - --storage.tsdb.retention.time=7d
    volumes:
      - ./configs/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro

  grafana:
    image: grafana/grafana:11.4.0
    ports:
      - "3000:3000"
    environment:
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Viewer
    volumes:
      - ./configs/grafana/provisioning:/etc/grafana/provisioning:ro
      - ./configs/grafana/dashboards:/var/lib/grafana/dashboards:ro
    depends_on:
      - prometheus

  # --- Airflow stack (make airflow-up) -------------------------------------

  airflow-db:
    image: postgres:15
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - airflow-db-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 10s
      timeout: 5s
      retries: 5
    profiles:
      - airflow

  airflow-init:
    <<: *airflow-common
    command: version
    environment:
      <<: *airflow-common-env
      _AIRFLOW_DB_MIGRATE: "true"
      _AIRFLOW_WWW_USER_CREATE: "true"
      _AIRFLOW_WWW_USER_USERNAME: admin
      _AIRFLOW_WWW_USER_PASSWORD: admin
    restart: "no"
    depends_on:
      airflow-db:
        condition: service_healthy

  airflow-apiserver:
    <<: *airflow-common
    command: api-server
    ports:
      - "8080:8080"
    depends_on:
      airflow-db:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/api/v2/version"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  airflow-dag-processor:
    <<: *airflow-common
    command: dag-processor
    depends_on:
      airflow-db:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully

  airflow-scheduler:
    <<: *airflow-common
    command: scheduler
    depends_on:
      airflow-db:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully

volumes:
  mlflow-data:
  airflow-db-data:
  airflow-logs:
